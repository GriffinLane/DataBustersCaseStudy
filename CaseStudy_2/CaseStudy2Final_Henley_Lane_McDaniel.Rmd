---
title: "Project"
author: "Griffin J. Lane"
date: "November 30, 2017"
output: html_document
---

```{r}
require(xlsx)
#Load in the dataset
workers <- read.xlsx("Casestudy2-data.xlsx", 1, header=TRUE, colClasses=NA)
```

```{r}
#Lets divide the data into a training set and a test set
#70% training and 30% test set is the recommended standard so we will use that
threshold <- nrow(workers)*.7

#subsets trainig sets first 70%
trainingSet <- workers[(1:threshold),]

#puts the remaining 30% into testSet
testSet <- workers[(threshold +1):nrow(workers),]

```

```{r}
#Now lets explore the data
summary(workers)

#Looks like there are a few columns with no standard deviation
#there are also quite a few factors to parse into dummy columns
#Employee number is a useless column for this analysis and should be dropped
```





```{r}
#lets make a function to parse out the columns with no deviations, make dummy columns for our factors,
#center and scale the data, and change the column names to a more readable format
#Also removes the extra columns generated by model.matrix in order to make the control group one of the factor values
PrepareData <- function(dataset, useControl){
  
  #Keep the original column count for iteration
  colCount <- ncol(dataset)
  
  #Instantiate a vector to store the original factor column indexes for removal
  toRemove <- c()
  
  #Instantiate a vector to store the new columns' indexes
  namesToChange <- c()
  
  #Instantiate a vector to store the new names. pairs with namesToChange.
  newNames <- c()
  
  #This vector stores the indexes of the control group from the newly generated dummy columns
  controlGroupIndex = c()
  
  #Instantiate at 1 since indexing starts at 1 in R *sigh*
  g <- 1
  
  #Get the names of all the original factor columns
  nameArr <- names(which(lapply(dataset,(is.factor))== TRUE)) 
  
  #Start a loop through each column
  for(i in (1:colCount))  {
    
    #Check to see if the column is a factor
    if(is.factor(dataset[,i])){
      #If it is a factor, make sure it has more than one factor value
      if(length(levels(dataset[,i]))>= 2){
        #Break factors into dummy columns and remove the intercept from the model.matrix
        mm <- model.matrix(~ dataset[,i]-1 , data=dataset)
        
        #Combine the dataset with these new columns using a cbind
        dataset <- cbind(dataset, mm)
      
        #Get the width of the newly added columns
        mm.width <- ncol(mm)
      
        #This line replaces part of the new column names with the original factor's column name
        #and adds it to a vector of new names
        newNames <- c(newNames,gsub("^(\\w+\\W+\\w)]", paste(nameArr[g], ".", sep = ""), x=names(dataset[,(ncol(dataset)+1-mm.width):ncol(dataset)])))
      
        #This line gets the newly added columns' indexes and adds them to the vector list 
        namesToChange <- c(namesToChange,((ncol(dataset)+1-mm.width):ncol(dataset)))
        
        #Adds the original factor column's index to a list of indexes to be removed from the data frame
        toRemove <- c(toRemove,i)
        
        #Indexes the first column created from the model matrix and marks it for deletion so
        #it can be represented by a 0 in the remaining columns' generated from the model matrix
        controlGroupIndex <- c(controlGroupIndex, (ncol(dataset)+1-mm.width))
        
        #increments the name iterator
        g <- g+1
      }
      else{
        #This Factor has only one value.
        #We can drop columns with only one factor
        #Adds this index to the list of indexes to be removed
        toRemove <- c(toRemove,i)
        #increments the name iterator
        g <- g+1
      }
    }
    #Converts this column to a numeric in case it is not already
    dataset[,i] <- as.numeric(dataset[,i])
    
    #This will center variables that have more than just 5 different values in them
    #This helps with interpretation
    if(length(levels(as.factor(dataset[,i]))) > 5)
    {
      #center numeric values and divide by sd
      dataset[,i] <- as.data.frame(scale(dataset[,i], center = TRUE, scale = TRUE))
    }
  }
  #Changes the names based on the vectors created in the for loop
  colnames(dataset)[namesToChange] <- newNames
  
  #Remove control/reference group
  dataset <- dataset[,-c(toRemove,controlGroupIndex)]
  
  #We don't need columns that have no variance
  datset <- Filter(function(x) sd(x) != 0, dataset)
  
  #Return the dataset
  dataset
}

#prepare the training set
empDat <- PrepareData(trainingSet)

#prepare the training set
testDat <- PrepareData(testSet)

#These are had all the same value for each record. EmployeeNumber is just unnecessary
empDat <- empDat[ -which(names(empDat) %in% c("EmployeeCount","StandardHours","StandardHours","EmployeeNumber"))]


head(empDat)
tail(empDat)
```


```{r}

#Lets generate a full model without interaction terms for simplicity's sake
fullmodel <- lm(Attrition.Yes ~ ., data = na.omit(empDat))

#This line iterates over the full model using the three techniques we have
#learned so far and select the best model for the nlm variable
nlm <- step(fullmodel, direction = c("both", "backward", "forward"), trace=FALSE ) 

#Lets view a summary of  the new linear model generated from Step()
summary(nlm)

```


```{r}
#lets see if the values remaining have strong coorelation to each other
library(corrgram) 

#Now lets explore the remaining columns and look for any colinearity
#In this way, we can simplify the model by removing one of the colinear variables since
#They can be represented by approximately the same line
corrgram(nlm$model, order=TRUE, lower.panel=panel.shade, 
   upper.panel=panel.density, text.panel=panel.txt, 
   main="Correlogram of Attrition Data (PC2/PC1 Order)")

```
```{r}
oldModel <- nlm$model
oldModel <- oldModel[-which(colnames(oldModel) %in% c("YearsAtCompany","Gender.Male","YearsWithCurrManager","BusinessTravel.Travel_Rarely"))]
head(oldModel)
#Lets generate a full model without interaction terms for simplicity's sake
fullmodel <- lm(Attrition.Yes ~ ., data = na.omit(oldModel))

#This line iterates over the full model using the three techniques we have
#learned so far and select the best model for the nlm variable
nlmStep <- step(fullmodel, direction = c("both", "backward", "forward"), trace=FALSE ) 

#Lets view a summary of  the new linear model generated from Step()
summary(nlmStep)
```


```{r}
library(MASS)
#The correlation between YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, and YearsWithCurrManager is
#Strong enough that they may be represented by approximately the same line
#Lets try removing YearsWithCurrentManager

plot(studres(nlm))
d1 <- cooks.distance(nlm)
r <- stdres(nlm)
a <- cbind(nlm$model, d1, r)

#Shows data points higher than my cook's D cutoff value of 4/n
a[a$d1 > 4/nrow(empDat),]
```

```{r}
#check the data's head
head(testSet,10)

#Calculate accuracy of prediction with test set data
sum(data.frame(round(predict(nlm,testDat))) == testDat$Attrition.Yes)/nrow(testDat)
```

```{r}
modelCoeffs <- data.frame(nlm$coefficients)

coeffs <- data.frame(Variable = rownames(modelCoeffs)[order(modelCoeffs)],Value = modelCoeffs[order(modelCoeffs),])
coeffs <- coeffs[order(coeffs$Value),]
coeffs
```

```{r}

topContributors <- coeffs[1:6,]
library(ggplot2)

#Make a plot and add the intercept value to show the slope when the regression formula is worked out
ggplot(data=topContributors, aes(x=Variable, y=abs(Value), fill = Variable)) +
  geom_bar(stat="identity")+
  ggtitle("Weakest Associations To Attrition")+xlab("Coefficient from Linear Model")+coord_flip()

```

#Kris Addition for test purposes
```{r}
#Grab the last few rows except for the intercept
bottomContributors <- coeffs[(nrow(coeffs)-6):nrow(coeffs)-1,]

#Create plot for the strongest contributors
ggplot(data=bottomContributors, aes(x=Variable, y=Value, fill = Variable)) +
  geom_bar(stat="identity")+
  ggtitle("Strong Associations")+xlab("Coefficient from Linear Model")+
  ylab("Coefficient Magnitude")+coord_flip()
```

